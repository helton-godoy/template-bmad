#!/usr/bin/env python3
"""
Teste comparativo: Llama3.2:3b vs Gemma3:4b
Compara qualidade de traduÃ§Ã£o e preservaÃ§Ã£o de formataÃ§Ã£o Markdown
"""

import ollama
import time

# Trecho de teste com todos os elementos problemÃ¡ticos
TEST_MARKDOWN = """## ğŸš€ Quick Reference Table

| Workflow | Agent | Track | Purpose |
| -------- | ----- | ----- | ------- |
| **create-ux-design** | UX Designer | BMad Method, Enterprise | Optional UX design |
| **architecture** | Architect | BMad Method, Enterprise | Technical architecture decisions |

### Complete User Journey

**Goal:** Add OAuth social login (Google, GitHub)

**Steps:**

1. **Start:** Load PM agent, say "I want to add OAuth social login"
2. **PM runs tech-spec workflow:**
   - Asks about the feature scope
   - You specify: Google and GitHub OAuth
   - Detects your stack (Next.js 13.4)
   - Generates:
     - tech-spec.md (implementation guide)
     - epics.md (OAuth Integration epic)
3. **Implement:** Load DEV agent
   - DEV implements backend OAuth
   - Done! ğŸ‘‰ ğŸ‰

**Total time:** 1-3 hours
"""

SYSTEM_PROMPT = """VocÃª Ã© um tradutor especializado em documentaÃ§Ã£o tÃ©cnica Markdown.

REGRAS CRÃTICAS:
1. Traduza APENAS o texto em inglÃªs para portuguÃªs brasileiro
2. PRESERVE COMPLETAMENTE a formataÃ§Ã£o Markdown original:
   - Mantenha todas as tabelas (pipes |)
   - Mantenha toda indentaÃ§Ã£o (espaÃ§os antes de -)
   - Mantenha todos os emojis
   - Mantenha todos os links
   - Mantenha todos os code blocks
   - Mantenha todos os hashtags (#, ##, ###)
3. NÃƒO adicione comentÃ¡rios ou explicaÃ§Ãµes
4. NÃƒO altere a estrutura do documento
5. Retorne APENAS o Markdown traduzido

Traduza o seguinte documento:"""

def test_model(model_name):
    """Testa um modelo com o trecho de teste"""
    print(f"\n{'='*70}")
    print(f"Testando modelo: {model_name}")
    print(f"{'='*70}\n")
    
    start_time = time.time()
    
    try:
        response = ollama.chat(
            model=model_name,
            messages=[
                {
                    'role': 'system',
                    'content': SYSTEM_PROMPT
                },
                {
                    'role': 'user',
                    'content': TEST_MARKDOWN
                }
            ],
            options={
                'temperature': 0.1,  # Baixa temperatura para traduÃ§Ã£o mais literal
                'top_p': 0.9,
            }
        )
        
        elapsed = time.time() - start_time
        result = response['message']['content']
        
        print(f"â±ï¸  Tempo: {elapsed:.1f}s")
        print(f"\nğŸ“„ Resultado:\n")
        print(result)
        
        # AnÃ¡lise de preservaÃ§Ã£o
        print(f"\n{'='*70}")
        print("AnÃ¡lise de PreservaÃ§Ã£o:")
        print(f"{'='*70}")
        
        checks = {
            "Tabelas (pipes |)": "|" in result,
            "Emojis (ğŸš€, ğŸ‘‰, ğŸ‰)": "ğŸš€" in result and "ğŸ‘‰" in result and "ğŸ‰" in result,
            "Hashtags (##, ###)": "##" in result,
            "IndentaÃ§Ã£o (   -)": "   -" in result,
            "Links/formataÃ§Ã£o": "**" in result,
        }
        
        for check, passed in checks.items():
            status = "âœ…" if passed else "âŒ"
            print(f"{status} {check}")
        
        success_rate = sum(checks.values()) / len(checks) * 100
        print(f"\nğŸ“Š Taxa de preservaÃ§Ã£o: {success_rate:.0f}%")
        
        return {
            'model': model_name,
            'time': elapsed,
            'result': result,
            'preservation_rate': success_rate,
            'checks': checks
        }
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        return None

def main():
    print("="*70)
    print("TESTE COMPARATIVO: Ollama Translation")
    print("="*70)
    print(f"\nğŸ“ Testando com trecho que contÃ©m:")
    print("  - Tabelas Markdown")
    print("  - Listas com indentaÃ§Ã£o")
    print("  - Emojis")
    print("  - FormataÃ§Ã£o (negrito, etc)")
    print("  - Hashtags de tÃ­tulos")
    
    models = ['llama3.2:3b', 'gemma3:4b']  # Note: gemma2 nÃ£o gemma3
    results = []
    
    for model in models:
        result = test_model(model)
        if result:
            results.append(result)
        time.sleep(2)  # Pequena pausa entre modelos
    
    # ComparaÃ§Ã£o final
    if len(results) == 2:
        print(f"\n\n{'='*70}")
        print("COMPARAÃ‡ÃƒO FINAL")
        print(f"{'='*70}\n")
        
        for r in results:
            print(f"Modelo: {r['model']}")
            print(f"  Tempo: {r['time']:.1f}s")
            print(f"  PreservaÃ§Ã£o: {r['preservation_rate']:.0f}%")
            print()
        
        # RecomendaÃ§Ã£o
        best = max(results, key=lambda x: x['preservation_rate'])
        fastest = min(results, key=lambda x: x['time'])
        
        print("ğŸ† RECOMENDAÃ‡ÃƒO:")
        print(f"  Melhor preservaÃ§Ã£o: {best['model']} ({best['preservation_rate']:.0f}%)")
        print(f"  Mais rÃ¡pido: {fastest['model']} ({fastest['time']:.1f}s)")
        
        if best['model'] == fastest['model']:
            print(f"\nâœ¨ {best['model']} Ã© o vencedor em ambos critÃ©rios!")
        else:
            print(f"\nâš–ï¸  Trade-off: Qualidade vs Velocidade")

if __name__ == "__main__":
    main()
